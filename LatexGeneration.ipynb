{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78be331-6011-48b2-a065-f00421d0124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataPreparationUtils as dpu\n",
    "from scipy.stats import gamma, lognorm, pareto\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as ro\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from rpy2.robjects import numpy2ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec7105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "import readDataV2\n",
    "import latexCodeGenV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0987bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = \"small\"\n",
    "nExperimentReptition = 10\n",
    "randomSeed = 20220222\n",
    "trueValue = 0.005\n",
    "dataDistributions = ['gamma', 'lognorm', 'pareto']\n",
    "dataSizes = [500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b92a5",
   "metadata": {},
   "source": [
    "## 1. Read data\n",
    "\n",
    "- Tail probability estimation with single threshold\n",
    "- Tail probability estimation with multiple thresholds\n",
    "- Quantile estimation with single threshold\n",
    "- Quantile estimation with multiple thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bceb56f-4d27-4b21-9977-213d238d6ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tb1 = readDataV2.tableOne().groupby(by=['dataDistribution','dataSize','percentageLHS','thresholdPercentage'])\n",
    "# tb2 = readDataV2.tableTwo().groupby(by=['dataDistribution','dataSize','quantitleValue','thresholdPercentage'])\n",
    "# tb31 = readDataV2.tableThreeOne().groupby(by=['dataDistribution','dataSize','percentageLHS','thresholdPercentage'])\n",
    "# tb32 = readDataV2.tableThreeTwo().groupby(by=['dataDistribution','dataSize','percentageLHS','thresholdPercentage'])\n",
    "# tb33 = readDataV2.tableThreeThree().groupby(by=['dataDistribution','dataSize','quantitleValue','thresholdPercentage'])\n",
    "# tb34 = readDataV2.tableThreeFour().groupby(by=['dataDistribution','dataSize','quantitleValue','thresholdPercentage'])\n",
    "# tb4 = readDataV2.tableFour().groupby(by=['dataDistribution','dataSize','percentageLHS','thresholdPercentage'])\n",
    "tb5 = pd.read_csv(os.path.join(FILE_DIR, 'tableFive_bayesian.csv')).groupby(by=['Data Source', 'nData', 'percentageLHS'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe2889",
   "metadata": {},
   "source": [
    "## Latex Code Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a26d3",
   "metadata": {},
   "source": [
    "## Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cbc22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSources = [\"gamma\",\"lognorm\", \"pareto\"]\n",
    "nDatas = [500]\n",
    "percentageLHS = 0.99\n",
    "thresholdPercentage = 0.70\n",
    "targetColumns = ['(0,CHI2)','(1,CHI2)','(2,CHI2)','(0,KS)','(1,KS)','(2,KS)']\n",
    "text_file = open(\"./robustTailTable/table1.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableOne(tb1, dataSources, nDatas, percentageLHS, thresholdPercentage, targetColumns, \n",
    "                   \"Tail probability estimation under different constraint settings. \",\n",
    "                   \"tb1_tpe\", 0.8).strip())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f77da",
   "metadata": {},
   "source": [
    "## Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea6c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSources = [\"gamma\",\"lognorm\", \"pareto\"]\n",
    "nDatas = [500]\n",
    "percentageLHS = 0.99\n",
    "thresholdPercentage = 0.70\n",
    "targetColumns = ['(0,CHI2)','(1,CHI2)','(2,CHI2)']\n",
    "text_file = open(\"./robustTailTable/table2.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableTwo(tb2, dataSources, nDatas, percentageLHS, thresholdPercentage, targetColumns, \n",
    "                   \"Quantile estimation under different constraint settings. \",\n",
    "                   \"tb2_qe\", 0.75).strip())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be86a83",
   "metadata": {},
   "source": [
    "## Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae87e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSources = [\"gamma\",\"lognorm\", \"pareto\"]\n",
    "nDatas = [500]\n",
    "percentageLHS = 0.99\n",
    "thresholdPercentages = 0.6\n",
    "targetColumns = ['(2,CHI2)']\n",
    "text_file = open(\"./robustTailTable/table3_tpe.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableThree(tb31, tb32, dataSources, nDatas, percentageLHS, thresholdPercentages, targetColumns, \n",
    "                   \"Tail probablity estimation under different cutoff threshold(s).\",\n",
    "                   \"tb3_tpe\", 0.75).strip())\n",
    "text_file = open(\"./robustTailTable/table3_qe.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableThree(tb33, tb34, dataSources, nDatas, percentageLHS, thresholdPercentages, targetColumns, \n",
    "                   \"Quantile estimation under different cutoff threshold(s). \",\n",
    "                   \"tb3_qe\", 0.75, True).strip())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8ce33",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d57c4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSources = [\"gamma\",\"lognorm\", \"pareto\"]\n",
    "nDatas = [500]\n",
    "percentageLHSs = np.linspace(0.9, 0.99, 10).tolist()\n",
    "thresholdPercentage = 0.7\n",
    "targetColumns = ['(2,CHI2)','(2,KS)']\n",
    "text_file = open(\"./robustTailTable/table4.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableFour(tb4, dataSources, nDatas, percentageLHSs, thresholdPercentage, targetColumns, \n",
    "                   \"Tail probability estimation under different objective functions. \",\n",
    "                   \"tb4_tpe_{:}\".format(thresholdPercentage),0.6).strip())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9b78e",
   "metadata": {},
   "source": [
    "## Table 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec548b-a44b-4b40-bdbd-355ed28c2980",
   "metadata": {},
   "source": [
    "## Peak over threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd5365d-1eb6-4cb0-ba3e-c7eaf0eaeb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSources = [\"gamma\",\"lognorm\", \"pareto\"]\n",
    "nDatas = [500]\n",
    "percentageLHSs = np.linspace(0.9, 0.95, 11).tolist()\n",
    "targetColumns = ['Upper Bound']\n",
    "text_file = open(\"./robustTailTable/table5.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableFive(tb5, dataSources, nDatas, percentageLHSs, targetColumns,\n",
    "                   \"Tail probability estimation using Peak-Over-Threshold.\",\n",
    "                   \"tb5_tpe_pot\",0.8).strip())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b28d5c-08bc-4636-8dd7-dc8206b0a9f0",
   "metadata": {},
   "source": [
    "## Profile likelihood method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb63dca8-5cf4-4e5f-95c9-7805c1a3a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSources = [\"gamma\",\"lognorm\", \"pareto\"]\n",
    "nDatas = [500]\n",
    "percentageLHSs = [0.9, 0.95, 0.99]\n",
    "targetColumns = ['Upper Bound']\n",
    "text_file = open(\"./robustTailTable/table5_w_pl.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableFive(tb5, dataSources, nDatas, percentageLHSs, targetColumns,\n",
    "                   \"Tail probability estimation using profile likelihood.\",\n",
    "                   \"tb5_tpe_profile_likelihood\",0.8).strip())\n",
    "text_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad9ac1-d8d7-41b2-9668-cca8dfa98e76",
   "metadata": {},
   "source": [
    "## Bayesian method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc385d7-d230-4f63-8c1a-a1488b77c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = 'large_table5_bayesian'\n",
    "df = pd.DataFrame()\n",
    "for percentageLHS in [\"0.9\", \"0.95\", \"0.99\"]:\n",
    "    for dataSource in [\"gamma\",\"lognorm\", \"pareto\"]:\n",
    "        df = pd.concat([df, pd.read_csv(f'{file_dir}/table5_{percentageLHS}_{dataSource}.csv')], axis=0)\n",
    "tb5 =  df.groupby(by=['Data Source', 'nData', 'percentageLHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfcff337-8d67-40e7-a67d-4db095930d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataSources = [\"gamma\",\"lognorm\", \"pareto\"]\n",
    "nDatas = [500]\n",
    "percentageLHSs = [0.9, 0.95, 0.99]\n",
    "targetColumns = ['Upper Bound']\n",
    "text_file = open(\"./robustTailTable/table5_w_bayesian.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableFive(tb5, dataSources, nDatas, percentageLHSs, targetColumns,\n",
    "                   \"Tail probability estimation using Bayesian.\",\n",
    "                   \"tb5_tpe_bayesian\",0.8).strip())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e23eb0-c6dd-4687-9f87-37766cca35f1",
   "metadata": {},
   "source": [
    "## Probability-weighted moment methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4413ec23-f958-4c32-b59b-a29a5a76551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b512df-3bd2-41e3-a444-203a65754f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = 'large_table5_pwm'\n",
    "df = pd.DataFrame()\n",
    "for percentageLHS in [\"0.9\", \"0.95\", \"0.99\"]:\n",
    "    for dataSource in [\"gamma\",\"lognorm\", \"pareto\"]:\n",
    "        df = pd.concat([df, pd.read_csv(f'{file_dir}/table5_{percentageLHS}_{dataSource}.csv')], axis=0)\n",
    "tb5 =  df.groupby(by=['Data Source', 'nData', 'percentageLHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31340e91-0ab4-4616-a330-8f494dc85b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataSources = [\"gamma\",\"lognorm\", \"pareto\"]\n",
    "nDatas = [500]\n",
    "percentageLHSs = [0.9, 0.95, 0.99]\n",
    "targetColumns = ['Upper Bound']\n",
    "text_file = open(\"./robustTailTable/table5_w_pwm.tex\", \"w\")\n",
    "text_file.write(latexCodeGenV2.getTableFive(tb5, dataSources, nDatas, percentageLHSs, targetColumns,\n",
    "                   \"Tail probability estimation using probability-weighted moment.\",\n",
    "                   \"tb5_tpe_pwm\",0.8).strip())\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
