{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "384a59b2-07fb-44ab-8b5a-e6f8c79d6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e7f69b-107d-4e43-9d35-e625c7a7bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = \"testResultSmall\"\n",
    "nExperimentReptition = 10\n",
    "randomSeed = 20220222\n",
    "trueValue = 0.005\n",
    "dataDistributions = ['gamma', 'lognorm', 'pareto']\n",
    "dataSizes = [500, 800]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1c2de-c38d-4f6c-9d58-341b3f224f02",
   "metadata": {},
   "source": [
    "### Tail probability estimation with single threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2526dc-2a31-4c47-9df9-72e20f9b1c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metaDataDict = {\"dataSize\": 500,\n",
    "                \"percentageLHS\": 0.99,\n",
    "                \"percentageRHS\": 0.995,\n",
    "                \"thresholdPercentage\": 0.7,\n",
    "                \"alpha\": 0.05,\n",
    "                \"gEllipsoidalDimension\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb611a4d-3e2f-4630-8031-81be6b05e9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresholdPercentages = np.linspace(0.6, 0.85, 11).tolist()\n",
    "# served as the lhsEndpoint in the objective function: 1_{lhs<=x<=rhs}.\n",
    "percentageLHSs = np.linspace(0.9, 0.99, 10).tolist()\n",
    "columnNames = ['dataDistribution','dataSize','percentageLHS', 'percentageRHS', \"thresholdPercentage\", \"trueValue\", \"nrepIndex\", \"(0,KS)\",\"(1,KS)\",\"(2,KS)\",\"(0,CHI2)\",\"(1,CHI2)\",\"(2,CHI2)\"]\n",
    "cumDf1 = pd.DataFrame(columns=columnNames)\n",
    "for dataDistribution, dataSize, percentageLHS, thresholdPercentage in itertools.product(*[dataDistributions, dataSizes, percentageLHSs, thresholdPercentages]):\n",
    "    metaDataDict[\"dataSize\"] = dataSize\n",
    "    metaDataDict[\"percentageLHS\"] = percentageLHS\n",
    "    metaDataDict[\"percentageRHS\"] = percentageLHS+trueValue\n",
    "    metaDataDict[\"thresholdPercentage\"] = thresholdPercentage\n",
    "    assert \"random_state\" not in metaDataDict\n",
    "    poolParamList = [(dataDistribution, metaDataDict, random_state+randomSeed)\n",
    "                     for random_state in range(nExperimentReptition)]\n",
    "    FILE_NAME = [\"tailProbabilityEstimation\"]\n",
    "    FILE_NAME += [\"dataDistribution=\"+dataDistribution]\n",
    "    FILE_NAME += [key+\"=\"+str(metaDataDict[key])\n",
    "                  for key in metaDataDict]\n",
    "    FILE_NAME += [\"randomSeed=\"+str(randomSeed)]\n",
    "    FILE_NAME += [\"nExperimentReptition=\"+str(nExperimentReptition)]\n",
    "    FILE_NAME = '_'.join(FILE_NAME)+\".csv\"\n",
    "    FILE_NAME = FILE_NAME.replace(\"00000000000001\",\"\").replace(\"0000000000001\",\"\")\n",
    "    df = pd.read_csv(os.path.join(FILE_DIR, FILE_NAME),\n",
    "                     index_col=\"Experiment Repetition Index\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"Experiment Repetition Index\":\"nrepIndex\"},inplace=True)\n",
    "    df[\"dataDistribution\"] = dataDistribution\n",
    "    df[\"dataSize\"] = dataSize\n",
    "    df[\"percentageLHS\"] = percentageLHS\n",
    "    df[\"percentageRHS\"] = percentageLHS+trueValue\n",
    "    df[\"thresholdPercentage\"] = thresholdPercentage\n",
    "    df[\"trueValue\"] = trueValue\n",
    "    cumDf1 = cumDf1.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b3d52-2944-4667-a441-183c57fd80a6",
   "metadata": {},
   "source": [
    "### Tail probability estimation with multiple thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96a24f6-f3d5-4889-9b7a-f04c32bdbbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholdPercentages = [0.6, 0.65, 0.70, 0.75, 0.8]\n",
    "# served as the lhsEndpoint in the objective function: 1_{lhs<=x<=rhs}.\n",
    "percentageLHSs = np.linspace(0.9, 0.99, 10).tolist()\n",
    "dataSizes = [500, 800]\n",
    "\n",
    "cumDf2 = pd.DataFrame(columns=columnNames)\n",
    "for dataDistribution, dataSize, percentageLHS, thresholdPercentage in itertools.product(*[dataDistributions, dataSizes, percentageLHSs, thresholdPercentages]):\n",
    "    metaDataDict[\"dataSize\"] = dataSize\n",
    "    metaDataDict[\"percentageLHS\"] = percentageLHS\n",
    "    metaDataDict[\"percentageRHS\"] = percentageLHS+trueValue\n",
    "    metaDataDict[\"thresholdPercentage\"] = [thresholdPercentage +\n",
    "                                           increment for increment in [0, 0.01, 0.02, 0.03, 0.04]]\n",
    "    assert \"random_state\" not in metaDataDict\n",
    "    poolParamList = [(dataDistribution, metaDataDict, random_state+randomSeed)\n",
    "                     for random_state in range(nExperimentReptition)]\n",
    "    FILE_NAME = [\"tailProbabilityEstimation\"]\n",
    "    FILE_NAME += [\"dataDistribution=\"+dataDistribution]\n",
    "    FILE_NAME += [key+\"=\"+str(metaDataDict[key])\n",
    "                  for key in metaDataDict]\n",
    "    FILE_NAME += [\"randomSeed=\"+str(randomSeed)]\n",
    "    FILE_NAME += [\"nExperimentReptition=\"+str(nExperimentReptition)]\n",
    "    FILE_NAME = '_'.join(FILE_NAME)+\".csv\"\n",
    "    FILE_NAME = FILE_NAME.replace(\"00000000000001\",\"\").replace(\"0000000000001\",\"\")\n",
    "    df = pd.read_csv(os.path.join(FILE_DIR, FILE_NAME),\n",
    "                     index_col=\"Experiment Repetition Index\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"Experiment Repetition Index\":\"nrepIndex\"},inplace=True)\n",
    "    df[\"dataDistribution\"] = dataDistribution\n",
    "    df[\"dataSize\"] = dataSize\n",
    "    df[\"percentageLHS\"] = percentageLHS\n",
    "    df[\"percentageRHS\"] = percentageLHS+trueValue\n",
    "    df[\"thresholdPercentage\"] = thresholdPercentage\n",
    "    df[\"trueValue\"] = trueValue\n",
    "    cumDf2 = cumDf2.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abccf2-2608-4cf0-a89a-c8d868634d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db064b28-593c-45f9-9e67-b92b0cc50ad7",
   "metadata": {},
   "source": [
    "### Quantile estimation with single threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f7f446-b2ba-4f72-bb85-07a2dae0cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataPreparationUtils as dpu\n",
    "from scipy.stats import gamma, lognorm, pareto, genpareto\n",
    "stringToDataModule = {\"gamma\": gamma,\n",
    "                      \"lognorm\": lognorm,\n",
    "                      \"pareto\": pareto,\n",
    "                      \"genpareto\": genpareto}\n",
    "metaDataDict = {\"dataSize\": 500,\n",
    "                \"quantitleValue\": 0.99,\n",
    "                \"thresholdPercentage\": 0.7,\n",
    "                \"alpha\": 0.05,\n",
    "                \"gEllipsoidalDimension\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9bc5abd-ee7c-4869-a55a-fa37ec639246",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholdPercentages = np.linspace(0.6, 0.85, 11).tolist()\n",
    "quantitleValues = np.linspace(0.9, 0.99, 10).tolist()\n",
    "dataSizes = [500, 800]\n",
    "columnNames = ['dataDistribution','dataSize','quantitleValue', \"thresholdPercentage\", \"trueValue\", \"nrepIndex\",\n",
    "               \"(0,CHI2)\",\"(1,CHI2)\",\"(2,CHI2)\"]\n",
    "\n",
    "cumDf3 = pd.DataFrame(columns=columnNames)\n",
    "for dataDistribution, dataSize, quantitleValue, thresholdPercentage in itertools.product(*[dataDistributions, dataSizes, quantitleValues, thresholdPercentages]):\n",
    "    metaDataDict[\"dataSize\"] = dataSize\n",
    "    metaDataDict[\"quantitleValue\"] = quantitleValue\n",
    "    metaDataDict[\"thresholdPercentage\"] = thresholdPercentage\n",
    "    assert \"random_state\" not in metaDataDict\n",
    "    poolParamList = [(dataDistribution, metaDataDict, random_state+randomSeed)\n",
    "                     for random_state in range(nExperimentReptition)]\n",
    "    FILE_NAME = [\"quantileEstimation\"]\n",
    "    FILE_NAME += [\"dataDistribution=\"+dataDistribution]\n",
    "    FILE_NAME += [key+\"=\"+str(metaDataDict[key])\n",
    "                  for key in metaDataDict]\n",
    "    FILE_NAME += [\"randomSeed=\"+str(randomSeed)]\n",
    "    FILE_NAME += [\"nExperimentReptition=\"+str(nExperimentReptition)]\n",
    "    FILE_NAME = '_'.join(FILE_NAME)+\".csv\"\n",
    "    FILE_NAME = FILE_NAME.replace(\"00000000000001\",\"\").replace(\"0000000000001\",\"\")\n",
    "    df = pd.read_csv(os.path.join(FILE_DIR, FILE_NAME),\n",
    "                     index_col=\"Experiment Repetition Index\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"Experiment Repetition Index\":\"nrepIndex\"},inplace=True)\n",
    "    df[\"dataDistribution\"] = dataDistribution\n",
    "    df[\"dataSize\"] = dataSize\n",
    "    df[\"quantitleValue\"] = quantitleValue\n",
    "    df[\"thresholdPercentage\"] = thresholdPercentage\n",
    "    trueValue = dpu.endPointGeneration(\n",
    "        stringToDataModule[dataDistribution], quantitleValue, dpu.dataModuleToDefaultParamDict[stringToDataModule[dataDistribution]])        \n",
    "    df[\"trueValue\"] = trueValue\n",
    "    \n",
    "    cumDf3 = cumDf3.append(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e6f64-a924-495e-8a43-582b59955eba",
   "metadata": {},
   "source": [
    "### Quantile estimation with multiple thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a189aa-b4f2-4dc4-9853-cf4b4413f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholdPercentages = [0.6, 0.65, 0.70, 0.75, 0.8]\n",
    "quantitleValues = np.linspace(0.9, 0.99, 10).tolist()\n",
    "dataSizes = [500, 800]\n",
    "columnNames = ['dataDistribution','dataSize','quantitleValue', \"thresholdPercentage\", \"trueValue\", \"nrepIndex\",\n",
    "               \"(0,CHI2)\",\"(1,CHI2)\",\"(2,CHI2)\"]\n",
    "\n",
    "cumDf4 = pd.DataFrame(columns=columnNames)\n",
    "for dataDistribution, dataSize, quantitleValue, thresholdPercentage in itertools.product(*[dataDistributions, dataSizes, quantitleValues, thresholdPercentages]):\n",
    "    metaDataDict[\"dataSize\"] = dataSize\n",
    "    metaDataDict[\"quantitleValue\"] = quantitleValue\n",
    "    metaDataDict[\"thresholdPercentage\"] = [thresholdPercentage +\n",
    "                                           increment for increment in [0, 0.01, 0.02, 0.03, 0.04]]\n",
    "    assert \"random_state\" not in metaDataDict\n",
    "    poolParamList = [(dataDistribution, metaDataDict, random_state+randomSeed)\n",
    "                     for random_state in range(nExperimentReptition)]\n",
    "    FILE_NAME = [\"quantileEstimation\"]\n",
    "    FILE_NAME += [\"dataDistribution=\"+dataDistribution]\n",
    "    FILE_NAME += [key+\"=\"+str(metaDataDict[key])\n",
    "                  for key in metaDataDict]\n",
    "    FILE_NAME += [\"randomSeed=\"+str(randomSeed)]\n",
    "    FILE_NAME += [\"nExperimentReptition=\"+str(nExperimentReptition)]\n",
    "    FILE_NAME = '_'.join(FILE_NAME)+\".csv\"\n",
    "    FILE_NAME = FILE_NAME.replace(\"00000000000001\",\"\").replace(\"0000000000001\",\"\")\n",
    "    df = pd.read_csv(os.path.join(FILE_DIR, FILE_NAME),\n",
    "                     index_col=\"Experiment Repetition Index\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"Experiment Repetition Index\":\"nrepIndex\"},inplace=True)\n",
    "    df[\"dataDistribution\"] = dataDistribution\n",
    "    df[\"dataSize\"] = dataSize\n",
    "    df[\"quantitleValue\"] = quantitleValue\n",
    "    df[\"thresholdPercentage\"] = thresholdPercentage    \n",
    "    trueValue = dpu.endPointGeneration(\n",
    "        stringToDataModule[dataDistribution], quantitleValue, dpu.dataModuleToDefaultParamDict[stringToDataModule[dataDistribution]])    \n",
    "    df[\"trueValue\"] = trueValue\n",
    "    \n",
    "    cumDf4 = cumDf4.append(df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3c0df29f-82ec-4a68-b3d3-cae5a973725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "go1 = cumDf1.groupby(by=['dataDistribution','dataSize','percentageLHS','thresholdPercentage'])\n",
    "go2 = cumDf2.groupby(by=['dataDistribution','dataSize','percentageLHS','thresholdPercentage'])\n",
    "go3 = cumDf3.groupby(by=['dataDistribution','dataSize','quantitleValue','thresholdPercentage'])\n",
    "go4 = cumDf4.groupby(by=['dataDistribution','dataSize','quantitleValue','thresholdPercentage'])\n",
    "# dictGO_key = list(dictGO.keys())\n",
    "# dictGO_value = list(dictGO.values())\n",
    "# using the variable axs for multiple Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2f12409-28ce-4731-9df2-a0bbfe5cd546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getSignificanceNExponent (value: float):\n",
    "        exponent = np.floor(np.log(value)/np.log(10))\n",
    "        return (value/10**exponent, exponent)\n",
    "    \n",
    "def tableFiveOneUnit(targetColumns, EstimatedUpperBound, RelativeRatio, CoverageProbability):\n",
    "    content = r\"\"\n",
    "    for i, targetColumn in enumerate(targetColumns):\n",
    "        significance, exponent = getSignificanceNExponent(EstimatedUpperBound[i])\n",
    "        if targetColumn == '(0,CHI2)':\n",
    "            content+=r\"$(0,\\chi^2)$ & ${:.2f}/{:.2f}\\times 10^{{{:d}}}$ & ${:2g}$\".format(RelativeRatio[i], significance, int(exponent),CoverageProbability[i])+'''\\\\\\\\\n",
    "        '''\n",
    "        elif targetColumn == '(1,CHI2)':\n",
    "            content+=r\"$(1,\\chi^2)$ & ${:.2f}/{:.2f}\\times 10^{{{:d}}}$ & ${:2g}$\".format(RelativeRatio[i], significance, int(exponent),CoverageProbability[i])+'''\\\\\\\\\n",
    "        '''\n",
    "        elif targetColumn == '(2,CHI2)':\n",
    "            content+=r\"$(2,\\chi^2)$ & ${:.2f}/{:.2f}\\times 10^{{{:d}}}$ & ${:2g}$\".format(RelativeRatio[i], significance, int(exponent),CoverageProbability[i])+'''\\\\\\\\\n",
    "        '''\n",
    "        elif targetColumn == '(0,KS)':\n",
    "            content+=r\"$(0,\\text{{KS}})$ & ${:.2f}/{:.2f}\\times 10^{{{:d}}}$ & ${:2g}$\".format(RelativeRatio[i], significance, int(exponent),CoverageProbability[i])+'''\\\\\\\\\n",
    "        '''\n",
    "        elif targetColumn == '(1,KS)':\n",
    "            content+=r\"$(1,\\text{{KS}})$ & ${:.2f}/{:.2f}\\times 10^{{{:d}}}$ & ${:2g}$\".format(RelativeRatio[i], significance, int(exponent),CoverageProbability[i])+'''\\\\\\\\\n",
    "        '''\n",
    "        elif targetColumn == '(2,KS)':\n",
    "            content+=r\"$(2,\\text{{KS}})$ & ${:.2f}/{:.2f}\\times 10^{{{:d}}}$ & ${:2g}$\".format(RelativeRatio[i], significance, int(exponent),CoverageProbability[i])+'''\\\\\\\\\n",
    "        '''\n",
    "        else:\n",
    "            print(targetColumn)\n",
    "            assert False\n",
    "    return content\n",
    "\n",
    "def tableFiveOneSubTable(content, subtableTitle, subtableLabel, textwidth):\n",
    "    return r\"\\begin{subtable}\"+r\"{{{:}\\textwidth}}\".format(textwidth)+\\\n",
    "        r'''\\begin{tabular}{ccc}\n",
    "        \\toprule\n",
    "        \\hline\n",
    "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
    "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
    "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
    "        '''+\\\n",
    "    content+\\\n",
    "    r'''\\hline\n",
    "    \\bottomrule\n",
    "    \\end{tabular}\n",
    "    '''+\\\n",
    "    r'''\\caption{{{:}}}\n",
    "    '''.format(subtableTitle)+\\\n",
    "    r'''\\label{{{:}}}\n",
    "    '''.format(subtableLabel)+\\\n",
    "    r'''\\end{subtable}\n",
    "    '''    \n",
    "\n",
    "# tableFiveOneUnit(targetColumns, EstimatedUpperBound, RelativeRatio, CoverageProbability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59f983a0-07f4-4091-a7d0-47d3d388fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetColumns = ['(0,CHI2)','(1,CHI2)','(2,CHI2)']\n",
    "# #                  '(1,KS)','(2,KS)']\n",
    "# keyChoice1 = ('gamma', 500, 0.99, 0.7)\n",
    "# keyChoice2 = ('gamma', 800, 0.99, 0.7)\n",
    "# go3.get_group(keyChoice1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "584ed350-4964-49a9-a99b-2350e3a08aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def tableFiveOne(groupby_object:pd.core.groupby.generic.DataFrameGroupBy, targetColumns:list,\n",
    "                 keyChoice1:tuple, keyChoice2:tuple, \n",
    "                 subTableTitle1:str, subTableLabel1:str, subTableTitle2:str, subTableLabel2:str,\n",
    "                 tableTitle:str, tableLabel:str, scalebox:float = 0.7, textwidth:float=0.7):\n",
    "    trueValue1 = groupby_object.get_group(keyChoice1)['trueValue'].unique()\n",
    "    RelativeRatio1 = (groupby_object.get_group(keyChoice1)[targetColumns].mean()/trueValue1).values\n",
    "    EstimatedUpperBound1 = groupby_object.get_group(keyChoice1)[targetColumns].mean().values\n",
    "    CoverageProbability1 = (groupby_object.get_group(keyChoice1)[targetColumns]>trueValue1[0]).mean().values\n",
    "    trueValue2 = groupby_object.get_group(keyChoice2)['trueValue'].unique()\n",
    "    RelativeRatio2 = (groupby_object.get_group(keyChoice2)[targetColumns].mean()/trueValue2).values\n",
    "    EstimatedUpperBound2 = groupby_object.get_group(keyChoice2)[targetColumns].mean().values\n",
    "    CoverageProbability2 = (groupby_object.get_group(keyChoice2)[targetColumns]>trueValue2[0]).mean().values\n",
    "    #We assume that subTable1 and subTable2 have the same true value. \n",
    "    latexTable = r'''\n",
    "    \\begin{table}[ht]\n",
    "    \\centering'''+\\\n",
    "    r'''\\scalebox{{{:}}}{{\n",
    "    '''.format(scalebox)+\\\n",
    "    tableFiveOneSubTable(\n",
    "        tableFiveOneUnit(targetColumns, EstimatedUpperBound1, RelativeRatio1, CoverageProbability1),\n",
    "        subTableTitle1, subTableLabel1, textwidth)+\\\n",
    "    r'''\\quad\\quad\\quad\\quad\n",
    "    '''+\\\n",
    "    tableFiveOneSubTable(\n",
    "        tableFiveOneUnit(targetColumns, EstimatedUpperBound2, RelativeRatio2, CoverageProbability2),\n",
    "        subTableTitle2, subTableLabel2, textwidth)+\\\n",
    "    r\"}\"+\\\n",
    "    r'''\\caption{{{:}}}\n",
    "    '''.format(tableTitle+\"True value is {:g}.\".format(trueValue1[0]))+\\\n",
    "    r'''\\label{{{:}}}\n",
    "    '''.format(tableLabel)+\\\n",
    "    r'''\\end{table}'''\n",
    "    return latexTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f3ab4b9d-21ce-49a7-8163-f531524e4703",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{table}[ht]\n",
      "    \\centering\\scalebox{0.7}{\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $16.08/8.04\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $5.46/2.73\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $2.99/1.50\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(0,\\text{KS})$ & $14.23/7.11\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\text{KS})$ & $6.64/3.32\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\text{KS})$ & $3.95/1.98\\times 10^{-2}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $500$. }\n",
      "    \\label{stb11_tpe_gamma}\n",
      "    \\end{subtable}\n",
      "    \\quad\\quad\\quad\\quad\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $14.19/7.10\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $5.00/2.50\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $2.76/1.38\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(0,\\text{KS})$ & $11.65/5.83\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\text{KS})$ & $5.90/2.95\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\text{KS})$ & $3.54/1.77\\times 10^{-2}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $800$. }\n",
      "    \\label{stb12_tpe_gamma}\n",
      "    \\end{subtable}\n",
      "    }\\caption{Tail probablity estimation from Gamma data source. True value is 0.005.}\n",
      "    \\label{stb1_tpe_gamma}\n",
      "    \\end{table}\n",
      "\n",
      "    \\begin{table}[ht]\n",
      "    \\centering\\scalebox{0.7}{\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $15.75/7.88\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $6.35/3.18\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $3.93/1.96\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(0,\\text{KS})$ & $14.11/7.05\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\text{KS})$ & $7.94/3.97\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\text{KS})$ & $5.06/2.53\\times 10^{-2}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $500$. }\n",
      "    \\label{stb11_tpe_lognormal}\n",
      "    \\end{subtable}\n",
      "    \\quad\\quad\\quad\\quad\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $16.98/8.49\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $6.58/3.29\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $3.99/2.00\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(0,\\text{KS})$ & $11.55/5.78\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\text{KS})$ & $6.98/3.49\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\text{KS})$ & $4.46/2.23\\times 10^{-2}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $800$. }\n",
      "    \\label{stb12_tpe_lognormal}\n",
      "    \\end{subtable}\n",
      "    }\\caption{Tail probablity estimation from Lognormal data source. True value is 0.005.}\n",
      "    \\label{tb1_tpe_lognormal}\n",
      "    \\end{table}\n",
      "\n",
      "    \\begin{table}[ht]\n",
      "    \\centering\\scalebox{0.7}{\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $14.78/7.39\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $6.39/3.20\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $4.29/2.15\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(0,\\text{KS})$ & $13.63/6.81\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\text{KS})$ & $8.85/4.43\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\text{KS})$ & $5.95/2.98\\times 10^{-2}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $500$. }\n",
      "    \\label{stb11_tpe_pareto}\n",
      "    \\end{subtable}\n",
      "    \\quad\\quad\\quad\\quad\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $14.92/7.46\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $6.44/3.22\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $4.23/2.11\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(0,\\text{KS})$ & $11.15/5.58\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(1,\\text{KS})$ & $7.59/3.79\\times 10^{-2}$ & $ 1$\\\\\n",
      "        $(2,\\text{KS})$ & $5.14/2.57\\times 10^{-2}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $800$. }\n",
      "    \\label{stb12_tpe_pareto}\n",
      "    \\end{subtable}\n",
      "    }\\caption{Tail probablity estimation from Pareto data source. True value is 0.005.}\n",
      "    \\label{tb1_tpe_pareto}\n",
      "    \\end{table}\n",
      "\n",
      "    \\begin{table}[ht]\n",
      "    \\centering\\scalebox{0.7}{\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $1.83/2.07\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $1.35/1.53\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $1.27/1.44\\times 10^{1}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $500$. }\n",
      "    \\label{stb11_qe_gamma}\n",
      "    \\end{subtable}\n",
      "    \\quad\\quad\\quad\\quad\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $1.75/1.98\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $1.30/1.47\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $1.22/1.38\\times 10^{1}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $800$. }\n",
      "    \\label{stb12_qe_gamma}\n",
      "    \\end{subtable}\n",
      "    }\\caption{Quantitle estimation from Gamma data source. True value is 11.3147.}\n",
      "    \\label{stb1_qe_gamma}\n",
      "    \\end{table}\n",
      "\n",
      "    \\begin{table}[ht]\n",
      "    \\centering\\scalebox{0.7}{\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $2.64/2.71\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $1.87/1.92\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $1.75/1.80\\times 10^{1}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $500$. }\n",
      "    \\label{stb11_qe_lognormal}\n",
      "    \\end{subtable}\n",
      "    \\quad\\quad\\quad\\quad\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $2.92/2.99\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $2.06/2.11\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $1.93/1.98\\times 10^{1}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $800$. }\n",
      "    \\label{stb12_qe_lognormal}\n",
      "    \\end{subtable}\n",
      "    }\\caption{Quantitle estimation from Lognormal data source. True value is 10.2405.}\n",
      "    \\label{stb1_qe_lognormal}\n",
      "    \\end{table}\n",
      "\n",
      "    \\begin{table}[ht]\n",
      "    \\centering\\scalebox{0.7}{\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $2.69/1.35\\times 10^{2}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $1.92/9.60\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $1.80/9.01\\times 10^{1}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $500$. }\n",
      "    \\label{stb11_qe_pareto}\n",
      "    \\end{subtable}\n",
      "    \\quad\\quad\\quad\\quad\n",
      "    \\begin{subtable}{0.7\\textwidth}\\begin{tabular}{ccc}\n",
      "        \\toprule\n",
      "        \\hline\n",
      "        \\multicolumn{1}{p{2.8cm}}{Constraint setting} &\n",
      "        \\multicolumn{1}{p{3.9cm}}{Relative ratio/Estimated UpperBound}  &\n",
      "        \\multicolumn{1}{p{2cm}}{Converage probability}  \\\\\\hline\n",
      "        $(0,\\chi^2)$ & $2.73/1.37\\times 10^{2}$ & $ 1$\\\\\n",
      "        $(1,\\chi^2)$ & $1.94/9.72\\times 10^{1}$ & $ 1$\\\\\n",
      "        $(2,\\chi^2)$ & $1.83/9.13\\times 10^{1}$ & $ 1$\\\\\n",
      "        \\hline\n",
      "    \\bottomrule\n",
      "    \\end{tabular}\n",
      "    \\caption{Data sample size = $800$. }\n",
      "    \\label{stb12_qe_pareto}\n",
      "    \\end{subtable}\n",
      "    }\\caption{Quantitle estimation from Pareto data source. True value is 50.}\n",
      "    \\label{stb1_qe_pareto}\n",
      "    \\end{table}\n"
     ]
    }
   ],
   "source": [
    "targetColumns = ['(0,CHI2)','(1,CHI2)','(2,CHI2)','(0,KS)','(1,KS)','(2,KS)']\n",
    "keyChoice1 = ('gamma', 500, 0.99, 0.7)\n",
    "keyChoice2 = ('gamma', 800, 0.99, 0.7)\n",
    "subTableTitle1 = r\"Data sample size = $500$. \"\n",
    "subTableLabel1 = \"stb11_tpe_gamma\"\n",
    "subTableTitle2 = r\"Data sample size = $800$. \"\n",
    "subTableLabel2 = \"stb12_tpe_gamma\"\n",
    "tableTitle = r\"Tail probablity estimation from Gamma data source. \"\n",
    "tableLabel = \"stb1_tpe_gamma\"\n",
    "print(tableFiveOne(go1, targetColumns, keyChoice1, keyChoice2, subTableTitle1, subTableLabel1, subTableTitle2, subTableLabel2, tableTitle, tableLabel))\n",
    "keyChoice1 = ('lognorm', 500, 0.99, 0.7)\n",
    "keyChoice2 = ('lognorm', 800, 0.99, 0.7)\n",
    "subTableTitle1 = r\"Data sample size = $500$. \"\n",
    "subTableLabel1 = \"stb11_tpe_lognormal\"\n",
    "subTableTitle2 = r\"Data sample size = $800$. \"\n",
    "subTableLabel2 = \"stb12_tpe_lognormal\"\n",
    "tableTitle = r\"Tail probablity estimation from Lognormal data source. \"\n",
    "tableLabel = \"tb1_tpe_lognormal\"\n",
    "print(tableFiveOne(go1, targetColumns, keyChoice1, keyChoice2, subTableTitle1, subTableLabel1, subTableTitle2, subTableLabel2, tableTitle, tableLabel))\n",
    "keyChoice1 = ('pareto', 500, 0.99, 0.7)\n",
    "keyChoice2 = ('pareto', 800, 0.99, 0.7)\n",
    "subTableTitle1 = r\"Data sample size = $500$. \"\n",
    "subTableLabel1 = \"stb11_tpe_pareto\"\n",
    "subTableTitle2 = r\"Data sample size = $800$. \"\n",
    "subTableLabel2 = \"stb12_tpe_pareto\"\n",
    "tableTitle = r\"Tail probablity estimation from Pareto data source. \"\n",
    "tableLabel = \"tb1_tpe_pareto\"\n",
    "print(tableFiveOne(go1, targetColumns, keyChoice1, keyChoice2, subTableTitle1, subTableLabel1, subTableTitle2, subTableLabel2, tableTitle, tableLabel))\n",
    "\n",
    "\n",
    "targetColumns = ['(0,CHI2)','(1,CHI2)','(2,CHI2)']\n",
    "#                  '(1,KS)','(2,KS)']\n",
    "keyChoice1 = ('gamma', 500, 0.99, 0.7)\n",
    "keyChoice2 = ('gamma', 800, 0.99, 0.7)\n",
    "subTableTitle1 = r\"Data sample size = $500$. \"\n",
    "subTableLabel1 = \"stb11_qe_gamma\"\n",
    "subTableTitle2 = r\"Data sample size = $800$. \"\n",
    "subTableLabel2 = \"stb12_qe_gamma\"\n",
    "tableTitle = r\"Quantitle estimation from Gamma data source. \"\n",
    "tableLabel = \"stb1_qe_gamma\"\n",
    "print(tableFiveOne(go3, targetColumns, keyChoice1, keyChoice2, subTableTitle1, subTableLabel1, subTableTitle2, subTableLabel2, tableTitle, tableLabel))\n",
    "\n",
    "targetColumns = ['(0,CHI2)','(1,CHI2)','(2,CHI2)']\n",
    "#                  '(1,KS)','(2,KS)']\n",
    "keyChoice1 = ('lognorm', 500, 0.99, 0.7)\n",
    "keyChoice2 = ('lognorm', 800, 0.99, 0.7)\n",
    "subTableTitle1 = r\"Data sample size = $500$. \"\n",
    "subTableLabel1 = \"stb11_qe_lognormal\"\n",
    "subTableTitle2 = r\"Data sample size = $800$. \"\n",
    "subTableLabel2 = \"stb12_qe_lognormal\"\n",
    "tableTitle = r\"Quantitle estimation from Lognormal data source. \"\n",
    "tableLabel = \"stb1_qe_lognormal\"\n",
    "print(tableFiveOne(go3, targetColumns, keyChoice1, keyChoice2, subTableTitle1, subTableLabel1, subTableTitle2, subTableLabel2, tableTitle, tableLabel))\n",
    "\n",
    "\n",
    "targetColumns = ['(0,CHI2)','(1,CHI2)','(2,CHI2)']\n",
    "#                  '(1,KS)','(2,KS)']\n",
    "keyChoice1 = ('pareto', 500, 0.99, 0.7)\n",
    "keyChoice2 = ('pareto', 800, 0.99, 0.7)\n",
    "subTableTitle1 = r\"Data sample size = $500$. \"\n",
    "subTableLabel1 = \"stb11_qe_pareto\"\n",
    "subTableTitle2 = r\"Data sample size = $800$. \"\n",
    "subTableLabel2 = \"stb12_qe_pareto\"\n",
    "tableTitle = r\"Quantitle estimation from Pareto data source. \"\n",
    "tableLabel = \"stb1_qe_pareto\"\n",
    "print(tableFiveOne(go3, targetColumns, keyChoice1, keyChoice2, subTableTitle1, subTableLabel1, subTableTitle2, subTableLabel2, tableTitle, tableLabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "eb02329f-59a9-4f62-b6aa-92bcb305dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableFiveThreeUnit(thresholds, EstimatedUpperBound, RelativeRatio, CoverageProbability):\n",
    "    content = r\"\"\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        significance0, exponent0 = getSignificanceNExponent(EstimatedUpperBound[i][0])\n",
    "        content+=r\"${:.3f}$ & ${:.2f}\\times 10^{{{:d}}}/{:.3f}/{:2g}$ \".format(threshold, significance0, int(exponent0), RelativeRatio[i][0], CoverageProbability[i][0])+'''\\\\\\\\\n",
    "        '''\n",
    "    significance0, exponent0 = getSignificanceNExponent(EstimatedUpperBound[-1][0])\n",
    "    content+=r\"${:}$ & ${:.2f}\\times 10^{{{:d}}}/{:.3f}/{:3g}$ \".format([round(threshod,3) for threshod in thresholds], significance0, int(exponent0), RelativeRatio[-1][0], CoverageProbability[-1][0]\n",
    "                                                                                                                )+'''\\\\\\\\\n",
    "        '''\n",
    "    return content\n",
    "\n",
    "def tableFiveThreeSubTable(content, subtableTitle, subtableLabel, textwidth):\n",
    "    return r\"\\begin{subtable}\"+r\"{{{:}\\textwidth}}\".format(textwidth)+\\\n",
    "        r'''\\begin{tabular}{ccc}\n",
    "        \\toprule\n",
    "        \\hline\n",
    "        \\multicolumn{1}{c}{Thresholds} &\n",
    "        \\multicolumn{1}{c}{$(2,\\chi^2)$}   \\\\\\hline\n",
    "        '''+\\\n",
    "    content+\\\n",
    "    r'''\\hline\n",
    "    \\bottomrule\n",
    "    \\end{tabular}\n",
    "    '''+\\\n",
    "    r'''\\caption{{{:}}}\n",
    "    '''.format(subtableTitle)+\\\n",
    "    r'''\\label{{{:}}}\n",
    "    '''.format(subtableLabel)+\\\n",
    "    r'''\\end{subtable}\n",
    "    '''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "61753560-4e3d-4a01-b7ba-95c760c56d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableFiveThree(groupby_object1:pd.core.groupby.generic.DataFrameGroupBy, \n",
    "                   groupby_object2:pd.core.groupby.generic.DataFrameGroupBy,\n",
    "                   targetColumns:list,\n",
    "                 keyChoice1:tuple, keyChoice2:tuple, \n",
    "                 subTableTitle1:str, subTableLabel1:str, subTableTitle2:str, subTableLabel2:str,\n",
    "                 tableTitle:str, tableLabel:str, scalebox:float = 0.7, textwidth:float=0.7):\n",
    "    numMultiThreshold = 5\n",
    "    RelativeRatio1 = []\n",
    "    CoverageProbability1 = []\n",
    "    EstimatedUpperBound1 = []\n",
    "    trueValue1 = []\n",
    "    for idx in range(numMultiThreshold):\n",
    "        currKeyChoice = (*keyChoice1[:3],round(keyChoice1[3]+0.025*idx,3))\n",
    "        ## trueValue should be same among different numMultiThreshold. \n",
    "        trueValue1.append(groupby_object1.get_group(currKeyChoice)['trueValue'].unique()[0])\n",
    "        EstimatedUpperBound1.append(groupby_object1.get_group(currKeyChoice)[targetColumns].mean().tolist())\n",
    "        RelativeRatio1.append((groupby_object1.get_group(currKeyChoice)[targetColumns].mean().values/trueValue1[-1]).tolist())\n",
    "        CoverageProbability1.append((groupby_object1.get_group(currKeyChoice)[targetColumns].values>trueValue1[-1]).mean(axis=0).tolist())        \n",
    "    thresholds1 = [keyChoice1[3]+0.025*idx for idx in range(numMultiThreshold)]\n",
    "    ## trueValue should be same among different numMultiThreshold. \n",
    "    trueValue1.append(groupby_object2.get_group(keyChoice1)['trueValue'].unique()[0])\n",
    "    RelativeRatio1.append((groupby_object2.get_group(keyChoice1)[targetColumns].mean().values/trueValue1[-1]).tolist())\n",
    "    CoverageProbability1.append((groupby_object2.get_group(keyChoice1)[targetColumns].values>trueValue1[-1]).mean(axis=0).tolist())\n",
    "    assert np.unique(trueValue1).size == 1 \n",
    "    trueValue1 = trueValue1[0]\n",
    "    RelativeRatio2 = []\n",
    "    CoverageProbability2 = []\n",
    "    EstimatedUpperBound2 = []\n",
    "    trueValue2 = []\n",
    "    for idx in range(numMultiThreshold):\n",
    "        currKeyChoice = (*keyChoice2[:3], round(keyChoice2[3]+0.025*idx,3))\n",
    "        ## trueValue should be same among different numMultiThreshold. \n",
    "        trueValue2.append(groupby_object1.get_group(currKeyChoice)['trueValue'].unique()[0])\n",
    "        EstimatedUpperBound2.append(groupby_object1.get_group(currKeyChoice)[targetColumns].mean().tolist())\n",
    "        RelativeRatio2.append((groupby_object1.get_group(currKeyChoice)[targetColumns].mean().values/trueValue2[-1]).tolist())\n",
    "        CoverageProbability2.append((groupby_object1.get_group(currKeyChoice)[targetColumns].values>trueValue2[-1]).mean(axis=0).tolist())        \n",
    "    thresholds2 = [keyChoice2[3]+0.025*idx for idx in range(numMultiThreshold)]\n",
    "    ## trueValue should be same among different numMultiThreshold. \n",
    "    trueValue2.append(groupby_object2.get_group(keyChoice2)['trueValue'].unique()[0])\n",
    "    RelativeRatio2.append((groupby_object2.get_group(keyChoice2)[targetColumns].mean().values/trueValue2[-1]).tolist())\n",
    "    CoverageProbability2.append((groupby_object2.get_group(keyChoice1)[targetColumns].values>trueValue2[-1]).mean(axis=0).tolist())\n",
    "    assert np.unique(trueValue2).size == 1 \n",
    "    trueValue2 = trueValue2[0]\n",
    "    assert trueValue2==trueValue1\n",
    "    trueValue = trueValue1\n",
    "    del trueValue2, trueValue1\n",
    "    #We assume that subTable1 and subTable2 have the same true value. \n",
    "    latexTable = r'''\n",
    "    \\begin{table}[ht]\n",
    "    \\centering'''+\\\n",
    "    r'''\\scalebox{{{:}}}{{\n",
    "    '''.format(scalebox)+\\\n",
    "    tableFiveThreeSubTable(\n",
    "        tableFiveThreeUnit(thresholds1, EstimatedUpperBound1, RelativeRatio1, CoverageProbability1),\n",
    "        subTableTitle1, subTableLabel1, textwidth)+\\\n",
    "    r'''\\quad\\quad\\quad\\quad\n",
    "    '''+\\\n",
    "    tableFiveThreeSubTable(\n",
    "        tableFiveThreeUnit(thresholds2, EstimatedUpperBound2, RelativeRatio2, CoverageProbability2),\n",
    "        subTableTitle2, subTableLabel2, textwidth)+\\\n",
    "    r\"}\"+\\\n",
    "    r'''\\caption{{{:}}}\n",
    "    '''.format(tableTitle+\"True value is {:g}.\".format(trueValue))+\\\n",
    "    r'''\\label{{{:}}}\n",
    "    '''.format(tableLabel)+\\\n",
    "    r'''\\end{table}'''\n",
    "    return latexTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b425ee-4f3e-4296-acb5-a74e17b2fb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d86bb206-a0af-427f-b254-0e6aec1a9c4d",
   "metadata": {},
   "source": [
    "### 5.1 Selection of shape constraints. i.e. D=0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e42a9661-f640-4ec2-8e7c-732b4dcf540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b2e2ff-10f5-4548-8dd1-8c2566a2eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3,figsize=(24,12))\n",
    "ks1= []\n",
    "chi1 = []\n",
    "for key, eachDF in go1:\n",
    "    assert False\n",
    "#     print(\"KS: \"+ key[0]+\"with datasize={:}, percentageLHS={:} and thresholdPercentage={:}\".format(key[1],key[2],key[3]))\n",
    "    ks1.append((eachDF.mean(axis=0)[['(0,KS)','(1,KS)','(2,KS)']]/eachDF['trueValue'].unique()).tolist())\n",
    "#     print(\"CHI2: \"+ key[0]+\"with datasize={:}, percentageLHS={:} and thresholdPercentage={:}\".format(key[1],key[2],key[3])) \n",
    "    chi1.append((eachDF.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDF['trueValue'].unique()).tolist())\n",
    "axs[0][0].plot(pd.DataFrame(data=ks1,columns=[\"D=0\",\"D=1\",\"D=2\"]).transpose().values.tolist(),'--x')\n",
    "axs[0][0].set_title(\"KS, tail probability, single threshold, Relative Ratio (RE)\")\n",
    "axs[0][1].plot(pd.DataFrame(data=chi1,columns=[\"D=0\",\"D=1\",\"D=2\"]).transpose().values.tolist(),'--x')\n",
    "axs[0][1].set_title(\"Chi2, tail probability, single threshold, RE\")\n",
    "\n",
    "ks2= []\n",
    "chi2 = []\n",
    "for key, eachDF in go2:\n",
    "#     print(\"KS: \"+ key[0]+\"with datasize={:}, percentageLHS={:} and thresholdPercentage={:}\".format(key[1],key[2],key[3]))\n",
    "    ks2.append((eachDF.mean(axis=0)[['(0,KS)','(1,KS)','(2,KS)']]/eachDF['trueValue'].unique()).tolist())\n",
    "#     print(\"CHI2: \"+ key[0]+\"with datasize={:}, percentageLHS={:} and thresholdPercentage={:}\".format(key[1],key[2],key[3]))    \n",
    "    chi2.append((eachDF.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDF['trueValue'].unique()).tolist())\n",
    "axs[1][0].plot(pd.DataFrame(data=ks2,columns=[\"D=0\",\"D=1\",\"D=2\"]).transpose().values.tolist(),'--x')\n",
    "axs[1][0].set_title(\"KS, tail probability, multiple thresholds, RE\")\n",
    "axs[1][1].plot(pd.DataFrame(data=chi2,columns=[\"D=0\",\"D=1\",\"D=2\"]).transpose().values.tolist(),'--x')\n",
    "axs[1][1].set_title(\"Chi2, tail probability, multiple thresholds, RE\")\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axs[i][j].set_xticks([0, 1, 2])     \n",
    "        axs[i][j].set_xticklabels(['D=0', 'D=1', 'D=2'])\n",
    "\n",
    "chi3 = []      \n",
    "chi4 = []      \n",
    "for key, eachDF in go3:\n",
    "#     print(\"CHI2: \"+ key[0]+\"with datasize={:}, percentageLHS={:} and thresholdPercentage={:}\".format(key[1],key[2],key[3]))    \n",
    "    chi3.append((eachDF.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDF['trueValue'].unique()).tolist())\n",
    "for key, eachDF in go4:\n",
    "#     print(\"CHI2: \"+ key[0]+\"with datasize={:}, percentageLHS={:} and thresholdPercentage={:}\".format(key[1],key[2],key[3]))    \n",
    "    chi4.append((eachDF.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDF['trueValue'].unique()).tolist())\n",
    "axs[0][2].plot(pd.DataFrame(data=chi3,columns=[\"D=0\",\"D=1\",\"D=2\"]).transpose().values.tolist(),'--x')\n",
    "axs[0][2].set_title(\"Chi2, Quantitle Estimation, single threshold, RE\")\n",
    "axs[1][2].plot(pd.DataFrame(data=chi4,columns=[\"D=0\",\"D=1\",\"D=2\"]).transpose().values.tolist(),'--x')\n",
    "_=axs[1][2].set_title(\"Chi2, Quantitle Estimation, multiple thresholds, RE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43405e95-6d34-47d6-bd7b-9fadc6ada48f",
   "metadata": {},
   "source": [
    "### 5.2 Selection of shape constraints. i.e.  KS vs Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68208fa3-67be-4291-8a58-19594a93197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2,figsize=(16,6))\n",
    "ksvschi1= []\n",
    "for key, eachDF in go1:\n",
    "    eachDF_mean = eachDF.mean(axis=0)\n",
    "    ksvschi1.append([eachDF_mean['(0,CHI2)']/eachDF_mean['(0,KS)'],eachDF_mean['(1,CHI2)']/eachDF_mean['(1,KS)'],eachDF_mean['(2,CHI2)']/eachDF_mean['(2,KS)']])\n",
    "    del eachDF_mean\n",
    "ksvschi2= []    \n",
    "for key, eachDF in go2:\n",
    "    eachDF_mean = eachDF.mean(axis=0)\n",
    "    ksvschi2.append([eachDF_mean['(0,CHI2)']/eachDF_mean['(0,KS)'],eachDF_mean['(1,CHI2)']/eachDF_mean['(1,KS)'],eachDF_mean['(2,CHI2)']/eachDF_mean['(2,KS)']])\n",
    "    del eachDF_mean\n",
    "\n",
    "axs[0].plot(pd.DataFrame(data=ksvschi1,columns=[\"D=0\",\"D=1\",\"D=2\"]).transpose().values.tolist(),'--x')\n",
    "axs[0].set_title(\"Chi2vsKS, mean tail probability ratio, single threshold\")\n",
    "axs[1].plot(pd.DataFrame(data=ksvschi2,columns=[\"D=0\",\"D=1\",\"D=2\"]).transpose().values.tolist(),'--x')\n",
    "axs[1].set_title(\"Chi2vsKS, mean tail probability ratio, multiple thresholds\")\n",
    "for i in range(2):\n",
    "        axs[i].set_xticks([0, 1, 2])     \n",
    "        axs[i].set_xticklabels(['D=0', 'D=1', 'D=2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fdf14-88cc-43ae-b10c-89bb489398d8",
   "metadata": {},
   "source": [
    "### 5.3 Selection of Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b5575f9-9cff-4ad0-8f84-0b7ec372badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "go1 = cumDf1.groupby(by=['dataDistribution','dataSize','percentageLHS'])\n",
    "go2 = cumDf2.groupby(by=['dataDistribution','dataSize','percentageLHS'])\n",
    "go3 = cumDf3.groupby(by=['dataDistribution','dataSize','quantitleValue'])\n",
    "go4 = cumDf4.groupby(by=['dataDistribution','dataSize','quantitleValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f77028-d8ad-47a7-aff6-3c934336a7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, eachDF in go1:\n",
    "    resultPerthreshold = []\n",
    "    for thresholdPercentage, eachDFwThreshold in eachDF.groupby(by='thresholdPercentage'):\n",
    "        \n",
    "        eachDF_mean = eachDFwThreshold.mean(axis=0)[['(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwThreshold['trueValue'][0]\n",
    "        resultPerthreshold.append([thresholdPercentage]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"SingleThreshold data source is {:}, dataSize is {:}, percentageLHS is {:}\".format(key[0],key[1],key[2]))\n",
    "    display(pd.DataFrame(resultPerthreshold,columns=['thresholdPercentage','(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "\n",
    "for key, eachDF in go2:\n",
    "    resultPerthreshold = []\n",
    "    for thresholdPercentage, eachDFwThreshold in eachDF.groupby(by='thresholdPercentage'):\n",
    "        \n",
    "        eachDF_mean = eachDFwThreshold.mean(axis=0)[['(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwThreshold['trueValue'][0]\n",
    "        resultPerthreshold.append([thresholdPercentage]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"MultiThresholds data source is {:}, dataSize is {:}, percentageLHS is {:}\".format(key[0],key[1],key[2]))        \n",
    "    display(pd.DataFrame(resultPerthreshold,columns=['thresholdPercentage','(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "for key, eachDF in go3:\n",
    "    resultPerthreshold = []\n",
    "    for thresholdPercentage, eachDFwThreshold in eachDF.groupby(by='thresholdPercentage'):\n",
    "        \n",
    "        eachDF_mean = eachDFwThreshold.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwThreshold['trueValue'][0]\n",
    "        resultPerthreshold.append([thresholdPercentage]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"SingleThreshold data source is {:}, dataSize is {:}, quantitleValue is {:}\".format(key[0],key[1],key[2]))        \n",
    "    display(pd.DataFrame(resultPerthreshold,columns=['thresholdPercentage','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "for key, eachDF in go4:\n",
    "    resultPerthreshold = []\n",
    "    for thresholdPercentage, eachDFwThreshold in eachDF.groupby(by='thresholdPercentage'):\n",
    "        \n",
    "        eachDF_mean = eachDFwThreshold.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwThreshold['trueValue'][0]\n",
    "        resultPerthreshold.append([thresholdPercentage]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"MultiThresholds data source is {:}, dataSize is {:}, quantitleValue is {:}\".format(key[0],key[1],key[2]))                \n",
    "    display(pd.DataFrame(resultPerthreshold,columns=['thresholdPercentage','(0,CHI2)','(1,CHI2)','(2,CHI2)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360227c8-ca63-4028-8436-5e220b491f34",
   "metadata": {},
   "source": [
    "### 5.4 Selection of objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886b7f8a-d6b0-4e8f-8119-89e5d3bfc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "go1 = cumDf1.groupby(by=['dataDistribution','dataSize','thresholdPercentage'])\n",
    "go2 = cumDf2.groupby(by=['dataDistribution','dataSize','thresholdPercentage'])\n",
    "go3 = cumDf3.groupby(by=['dataDistribution','dataSize','thresholdPercentage'])\n",
    "go4 = cumDf4.groupby(by=['dataDistribution','dataSize','thresholdPercentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39cff050-febb-467d-b175-9f85f852d74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, eachDF in go1:\n",
    "    resultPercentage = []\n",
    "    for percentage, eachDFwP in eachDF.groupby(by='percentageLHS'):\n",
    "        eachDF_mean = eachDFwP.mean(axis=0)[['(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwP['trueValue'][0]\n",
    "        resultPercentage.append([percentage]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"SingleThreshold data source is {:}, dataSize is {:}, thresholdPercentage is {:}\".format(key[0],key[1],key[2]))        \n",
    "    display(pd.DataFrame(resultPercentage,columns=['ObjectiveLHS','(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "\n",
    "for key, eachDF in go2:\n",
    "    resultPercentage = []\n",
    "    for percentage, eachDFwP in eachDF.groupby(by='percentageLHS'):\n",
    "        eachDF_mean = eachDFwP.mean(axis=0)[['(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwP['trueValue'][0]\n",
    "        resultPercentage.append([percentage]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"MultiThresholds data source is {:}, dataSize is {:}, thresholdPercentage is {:}\".format(key[0],key[1],key[2]))                \n",
    "    display(pd.DataFrame(resultPercentage,columns=['ObjectiveLHS','(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "\n",
    "for key, eachDF in go3:\n",
    "    resultPercentage = []\n",
    "    for percentage, eachDFwP in eachDF.groupby(by='quantitleValue'):\n",
    "        eachDF_mean = eachDFwP.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwP['trueValue'][0]\n",
    "        resultPercentage.append([percentage]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"SingleThreshold data source is {:}, dataSize is {:}, thresholdPercentage is {:}\".format(key[0],key[1],key[2]))                \n",
    "    display(pd.DataFrame(resultPercentage,columns=['targetQuantile','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "\n",
    "for key, eachDF in go4:\n",
    "    resultPercentage = []\n",
    "    for percentage, eachDFwP in eachDF.groupby(by='quantitleValue'):\n",
    "        eachDF_mean = eachDFwP.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwP['trueValue'][0]\n",
    "        resultPercentage.append([percentage]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"MultiThresholds data source is {:}, dataSize is {:}, thresholdPercentage is {:}\".format(key[0],key[1],key[2]))                \n",
    "    display(pd.DataFrame(resultPercentage,columns=['targetQuantile','(0,CHI2)','(1,CHI2)','(2,CHI2)'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8c56c-9966-4964-940d-e15b2f47d807",
   "metadata": {},
   "source": [
    "### 5.5 Selection of data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f974180-396b-4f96-91d4-54011819b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "go1 = cumDf1.groupby(by=['dataSize','thresholdPercentage','percentageLHS'])\n",
    "go2 = cumDf2.groupby(by=['dataSize','thresholdPercentage','percentageLHS'])\n",
    "go3 = cumDf3.groupby(by=['dataSize','thresholdPercentage','quantitleValue'])\n",
    "go4 = cumDf4.groupby(by=['dataSize','thresholdPercentage','quantitleValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7180c5db-91d0-4c40-8403-a1d5889a3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, eachDF in go1:\n",
    "    result = []\n",
    "    for dataDistribution, eachDFwP in eachDF.groupby(by='dataDistribution'):\n",
    "        eachDF_mean = eachDFwP.mean(axis=0)[['(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwP['trueValue'].values[0]\n",
    "        result.append([dataDistribution]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"SingleThreshold data source is {:}, thresholdPercentage is {:}, percentageLHS is {:}\".format(key[0],key[1],key[2]))                        \n",
    "    display(pd.DataFrame(result,columns=['dataDistribution','(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "\n",
    "for key, eachDF in go2:\n",
    "    result = []\n",
    "    for dataDistribution, eachDFwP in eachDF.groupby(by='dataDistribution'):\n",
    "        eachDF_mean = eachDFwP.mean(axis=0)[['(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwP['trueValue'].values[0]\n",
    "        result.append([dataDistribution]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"MultiThresholds data source is {:}, thresholdPercentage is {:}, percentageLHS is {:}\".format(key[0],key[1],key[2]))                                \n",
    "    display(pd.DataFrame(result,columns=['dataDistribution','(0,KS)','(1,KS)','(2,KS)','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "for key, eachDF in go3:\n",
    "    result = []\n",
    "    for dataDistribution, eachDFwP in eachDF.groupby(by='dataDistribution'):\n",
    "        eachDF_mean = eachDFwP.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwP['trueValue'].values[0]\n",
    "        result.append([dataDistribution]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"SingleThreshold data source is {:}, thresholdPercentage is {:}, quantitleValue is {:}\".format(key[0],key[1],key[2]))                        \n",
    "    display(pd.DataFrame(result,columns=['dataDistribution','(0,CHI2)','(1,CHI2)','(2,CHI2)']))\n",
    "for key, eachDF in go4:\n",
    "    result = []\n",
    "    for dataDistribution, eachDFwP in eachDF.groupby(by='dataDistribution'):\n",
    "        eachDF_mean = eachDFwP.mean(axis=0)[['(0,CHI2)','(1,CHI2)','(2,CHI2)']]/eachDFwP['trueValue'].values[0]\n",
    "        result.append([dataDistribution]+list(eachDF_mean))\n",
    "        del eachDF_mean\n",
    "    print(\"MultiThresholds data source is {:}, thresholdPercentage is {:}, quantitleValue is {:}\".format(key[0],key[1],key[2]))                                \n",
    "    display(pd.DataFrame(result,columns=['dataDistribution','(0,CHI2)','(1,CHI2)','(2,CHI2)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1ebd3-e27f-45f2-aef8-529a868bed61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
